{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Tasks\n",
    "\n",
    "1. **Quantization Exploration (Tutorial 3)**\n",
    "   - In Tutorial 3, you quantized every Linear layer in the model to the provided configuration. Now, explore a range of fixed point widths from 4 to 32.  \n",
    "   - Plot a figure where:\n",
    "     - **x-axis:** Fixed point width  \n",
    "     - **y-axis:** Highest achieved accuracy on the IMDb dataset  \n",
    "     - Follow the procedure in Tutorial 3.  \n",
    "   - Plot separate curves for **PTQ** and **QAT** at each precision to show the effect of post-quantization finetuning.\n",
    "\n",
    "2. **Pruning Exploration (Tutorial 4)**\n",
    "   - Take your best obtained model from Task 1 and rerun the pruning procedure, varying the sparsity from 0.1 to 0.9.  \n",
    "   - Plot a figure where:\n",
    "     - **x-axis:** Sparsity  \n",
    "     - **y-axis:** Highest achieved accuracy on the IMDb dataset  \n",
    "     - Follow the procedure in Tutorial 4.  \n",
    "   - Plot separate curves for **Random** and **L1-Norm** methods to evaluate the effect of different pruning strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jw3621/anaconda3/envs/mase-adls/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -2.0138e+00,\n",
      "            4.5529e-01, -7.8171e-01],\n",
      "          [ 1.1969e+00,  1.6337e+00,  2.5047e-01,  ..., -8.1892e-01,\n",
      "            1.1978e+00,  2.1808e+00]],\n",
      "\n",
      "         [[ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -2.2501e-01,\n",
      "            7.2290e-02, -1.8290e+00],\n",
      "          [ 8.9952e-01,  1.0029e+00,  7.4536e-04,  ..., -6.3025e-01,\n",
      "           -1.5967e-01,  1.3284e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ...,  1.1867e+00,\n",
      "           -1.3561e+00,  6.5158e-01],\n",
      "          [ 9.5466e-01,  4.5887e-01,  7.8078e-01,  ..., -3.0983e-01,\n",
      "           -1.2971e-01,  1.1265e+00]],\n",
      "\n",
      "         [[ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ...,  6.5467e-01,\n",
      "           -6.8451e-01,  6.5081e-01],\n",
      "          [ 7.0729e-01,  1.4499e+00, -1.5089e-01,  ..., -1.3174e+00,\n",
      "            2.2258e-01,  8.8157e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-4.4781e-01, -7.9224e-01, -2.1741e+00,  ...,  1.7508e+00,\n",
      "           -3.6708e-01, -1.3251e+00],\n",
      "          [ 7.9208e-01, -1.3537e-01,  2.3756e-01,  ..., -5.9181e-01,\n",
      "            1.4373e+00,  2.4267e+00]],\n",
      "\n",
      "         [[-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -9.6646e-01,\n",
      "           -4.8876e-01, -1.4426e+00],\n",
      "          [ 1.0250e+00, -6.9093e-01, -1.2734e+00,  ..., -5.9773e-01,\n",
      "           -3.0482e-01,  1.4038e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.2252e-02,\n",
      "            1.0394e+00,  4.2402e-01],\n",
      "          [-4.7386e-01,  2.6401e+00,  1.7024e+00,  ..., -1.1508e+00,\n",
      "            7.5490e-01,  8.2911e-01]],\n",
      "\n",
      "         [[ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -6.1665e-01,\n",
      "            2.7627e-01, -1.2083e+00],\n",
      "          [ 9.3395e-01, -9.7541e-01, -2.5442e-02,  ..., -1.5233e+00,\n",
      "           -6.0733e-01,  3.3097e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-0.5842,  0.9588,  1.5642,  ..., -1.5431,  0.4999, -1.1350],\n",
      "          [ 0.9615,  0.8694,  0.0998,  ..., -1.0731, -0.7330,  0.3132]],\n",
      "\n",
      "         [[-0.8601, -1.3756,  0.5042,  ...,  0.9764, -0.8321, -1.0204],\n",
      "          [ 1.5175,  1.1454,  0.7791,  ..., -0.0476,  0.2650,  1.2150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0520,  1.1719, -1.5471,  ...,  1.9402, -1.1294,  0.4793],\n",
      "          [ 1.0053,  0.8099,  1.6415,  ..., -0.7894,  0.1419,  1.6964]],\n",
      "\n",
      "         [[ 0.7654, -1.5053, -0.4142,  ...,  1.7455, -0.7326,  1.5248],\n",
      "          [ 1.0806,  1.1457,  2.2163,  ..., -1.4622, -0.8975,  1.4576]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "\n",
      "\n",
      "        [[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-1.3806,  0.2626, -0.5207,  ...,  1.6517, -0.2316, -1.3171],\n",
      "          [ 0.6812, -0.0090,  0.3803,  ..., -1.6714, -0.0554,  1.0225]],\n",
      "\n",
      "         [[-1.7116,  1.8788, -2.5695,  ...,  0.4927, -0.4850, -1.0645],\n",
      "          [ 1.2646,  1.6481,  0.9055,  ..., -0.6958,  0.5728,  0.5461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3246,  1.2196, -0.3034,  ...,  1.2747,  1.2353,  0.2825],\n",
      "          [ 1.5373,  0.8648,  0.6062,  ..., -1.1955, -0.6708,  0.5128]],\n",
      "\n",
      "         [[ 0.9854,  0.8260,  0.2892,  ...,  1.3848, -0.0103, -1.0700],\n",
      "          [ 1.3827,  2.9809,  0.0276,  ..., -0.6428,  0.3637,  0.4339]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-1.1465, -1.5578, -0.6984,  ...,  0.0289, -2.1112, -0.8728],\n",
      "          [ 0.6506, -1.6966,  1.4463,  ...,  1.0310,  0.4824, -0.2291]],\n",
      "\n",
      "         [[-1.0361, -1.8192, -2.3055,  ..., -0.2195, -1.1732,  0.3182],\n",
      "          [-0.5841, -0.0227,  3.0901,  ...,  1.5286, -1.5941,  1.1762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7992,  0.0886,  0.4887,  ...,  0.7859, -1.0127, -0.2676],\n",
      "          [-0.3055,  0.6270, -3.0705,  ..., -1.7941,  0.4835,  1.3780]],\n",
      "\n",
      "         [[-1.4692, -0.9135, -0.2802,  ...,  0.1197, -0.7532,  0.0731],\n",
      "          [ 0.6096, -1.0893, -0.6959,  ..., -0.9691,  0.3500,  1.8863]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "\n",
      "\n",
      "        [[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-0.3700, -1.9754, -0.7315,  ...,  0.5756, -1.5559,  0.0326],\n",
      "          [ 1.4229,  2.3970, -0.4516,  ...,  0.2293,  0.6996,  3.1299]],\n",
      "\n",
      "         [[-0.6252,  0.2879, -1.4036,  ...,  0.5306, -0.5608,  1.1861],\n",
      "          [-2.5980,  0.2673,  3.3016,  ..., -2.0560, -2.4623, -0.9584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1306, -1.4343, -1.4422,  ...,  0.3918, -1.5336, -0.5026],\n",
      "          [ 1.8587,  0.8501, -1.2402,  ..., -1.6115, -0.0475,  1.3975]],\n",
      "\n",
      "         [[-0.9816, -1.4909, -1.0086,  ...,  0.2956,  0.0351, -1.0685],\n",
      "          [-0.6594, -0.0133, -1.1863,  ..., -0.9284,  0.5260,  1.5330]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          ...,\n",
      "          [-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026]],\n",
      "\n",
      "         [[-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990],\n",
      "          ...,\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          ...,\n",
      "          [-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201]],\n",
      "\n",
      "         [[ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721],\n",
      "          ...,\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382]],\n",
      "\n",
      "         [[-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508]],\n",
      "\n",
      "         [[-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980]],\n",
      "\n",
      "         [[-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046]],\n",
      "\n",
      "         [[-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391]],\n",
      "\n",
      "         [[-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617]],\n",
      "\n",
      "         [[-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792]],\n",
      "\n",
      "         [[-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687]],\n",
      "\n",
      "         [[-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0455,  0.6529,  0.6297,  ...,  1.0165, -1.6055,  0.0557],\n",
      "          [-0.9141, -1.5101, -0.8415,  ...,  0.4139, -0.9381,  0.6769]],\n",
      "\n",
      "         [[-3.1104, -3.7282, -2.3953,  ..., -1.6195,  0.7426, -3.2794],\n",
      "          [-1.2694,  0.3821, -0.5687,  ..., -0.9155, -0.8280, -1.7070]],\n",
      "\n",
      "         [[-0.9324, -2.9333, -2.3249,  ..., -1.0254,  1.8158, -1.8835],\n",
      "          [-1.5265, -0.3901,  0.2734,  ..., -0.8455, -0.0326, -0.6998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9000, -1.1028, -1.1281,  ..., -1.2688, -0.0851, -2.3190],\n",
      "          [-2.4374,  0.0718, -2.7276,  ..., -0.2809,  2.0206, -1.0802]],\n",
      "\n",
      "         [[-1.1088, -1.0420, -2.4026,  ..., -1.0658,  0.1932, -1.7012],\n",
      "          [-2.3622, -0.5291, -1.9931,  ..., -0.4478,  0.7391, -0.0354]],\n",
      "\n",
      "         [[ 0.7349,  0.6742, -2.6697,  ..., -1.4630, -0.1686, -2.5682],\n",
      "          [-0.1401, -0.9712, -2.3801,  ..., -0.5114,  1.5155,  2.0246]]],\n",
      "\n",
      "\n",
      "        [[[-0.0799,  0.7813,  0.4918,  ...,  1.2364, -1.9500, -0.1275],\n",
      "          [-0.4080, -1.5069, -0.8504,  ...,  0.6888, -0.7680,  0.9805]],\n",
      "\n",
      "         [[-2.8720, -1.0602, -2.3610,  ..., -2.3225, -0.0351, -2.7432],\n",
      "          [-0.2305, -0.5940, -1.1570,  ..., -2.1143,  0.9664, -1.1212]],\n",
      "\n",
      "         [[-1.4705, -2.1384, -1.9955,  ..., -0.6524, -1.8025, -1.8321],\n",
      "          [-1.7742, -0.6800, -0.2172,  ..., -0.9722,  1.5909, -0.1668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9884, -1.1566, -2.5215,  ..., -0.5054, -1.0314, -3.4883],\n",
      "          [-1.9535,  0.5573, -2.1564,  ...,  1.1460,  0.7120, -0.6320]],\n",
      "\n",
      "         [[-3.3666, -0.7966, -3.3154,  ...,  0.7587, -0.6289, -3.4848],\n",
      "          [-1.4099, -2.0919, -1.5870,  ...,  0.5316,  1.7058,  2.1950]],\n",
      "\n",
      "         [[ 0.6626,  0.8537, -2.7251,  ..., -1.1831, -0.7083, -2.7717],\n",
      "          [ 0.4486, -1.1639, -2.1203,  ..., -0.0901,  1.5883,  2.3840]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8947,  0.0412, -1.2359,  ...,  1.5140, -1.9812, -2.5532],\n",
      "          [-0.2951, -1.6086, -0.6381,  ...,  0.4410, -0.3965,  0.0106]],\n",
      "\n",
      "         [[-1.9196,  0.3326,  0.8482,  ..., -2.3348,  1.3935,  1.1452],\n",
      "          [-0.5277,  0.1234,  0.7865,  ..., -1.5790, -1.1817, -1.0156]],\n",
      "\n",
      "         [[-2.1664,  0.3959,  0.7476,  ..., -2.0817,  0.2852,  0.8173],\n",
      "          [-0.8414,  0.5154, -0.4553,  ..., -2.1767, -0.6488,  0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6009,  0.4887, -0.4818,  ..., -1.8165,  1.4764,  0.5091],\n",
      "          [-0.6869,  0.4007, -1.5818,  ..., -1.1268,  0.4111,  0.7892]],\n",
      "\n",
      "         [[-0.1528,  1.1728, -0.5164,  ..., -1.3611,  1.0621,  1.1810],\n",
      "          [-0.7595, -0.1699, -1.5305,  ..., -0.4340,  0.1499,  1.6704]],\n",
      "\n",
      "         [[ 1.0253,  1.4222, -0.1805,  ..., -0.6989,  0.4721,  2.6129],\n",
      "          [-1.2381, -0.4573, -1.7561,  ..., -0.6130, -0.5380,  1.6164]]],\n",
      "\n",
      "\n",
      "        [[[-0.6736, -0.0718, -1.1724,  ...,  1.4816, -1.7920, -2.5177],\n",
      "          [-0.3929, -1.5120, -0.5353,  ...,  0.2001, -0.5481,  0.0232]],\n",
      "\n",
      "         [[-1.8698, -1.2184,  0.2913,  ..., -1.5227,  1.9764,  0.6389],\n",
      "          [-0.4202,  0.4572, -1.0780,  ..., -1.1398, -1.3523, -0.7851]],\n",
      "\n",
      "         [[-1.3725, -0.8212,  0.1984,  ..., -2.1553,  1.7041,  0.7166],\n",
      "          [-1.0124,  0.9351, -0.0954,  ..., -1.8218, -1.4800, -0.2956]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5946,  0.5680,  0.8938,  ..., -2.1904,  1.7986,  1.0902],\n",
      "          [-1.3820,  1.0268, -1.0041,  ..., -1.6653,  0.8218,  1.1902]],\n",
      "\n",
      "         [[ 1.2800,  1.9566,  0.2540,  ..., -1.6180,  1.6176,  2.5636],\n",
      "          [-2.0592,  0.7059, -1.3359,  ..., -1.2290,  0.5257,  1.2667]],\n",
      "\n",
      "         [[ 1.3511,  1.3329, -0.0782,  ..., -0.5836,  0.6491,  2.6554],\n",
      "          [-1.3686, -0.2348, -1.7438,  ..., -0.8454, -0.7400,  1.5966]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8837e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0706e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3443e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8837e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0706e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3443e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.8307e-01,  1.8837e-02, -1.0314e+00,  ..., -8.0955e-01,\n",
      "           -2.8557e-01, -2.3318e-01],\n",
      "          [-9.9661e-02,  3.1722e-01, -3.0517e-01,  ...,  6.4335e-01,\n",
      "           -3.1830e-01, -1.7296e+00]],\n",
      "\n",
      "         [[ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ..., -7.9549e-01,\n",
      "           -6.9279e-01, -1.8082e-01],\n",
      "          [-9.9201e-01,  9.4938e-01,  4.4198e-02,  ...,  1.5973e+00,\n",
      "            1.1907e+00, -9.0454e-01]],\n",
      "\n",
      "         [[-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -1.8905e+00,\n",
      "            1.6226e-01, -1.2953e+00],\n",
      "          [-7.0312e-01, -6.4926e-01, -5.0913e-01,  ..., -5.3627e-01,\n",
      "           -1.0456e+00, -1.6301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7466e-01,  3.0706e-02,  7.5225e-01,  ..., -1.9281e+00,\n",
      "            1.1489e+00, -2.4530e-01],\n",
      "          [-7.6226e-02,  8.5814e-01, -1.5467e+00,  ..., -1.3217e+00,\n",
      "           -1.3415e+00, -3.8328e-01]],\n",
      "\n",
      "         [[ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -2.4168e+00,\n",
      "            3.3385e-01, -6.2115e-02],\n",
      "          [-1.6390e+00, -1.6085e-01, -1.9118e+00,  ..., -1.6600e-01,\n",
      "           -6.5011e-01,  2.1798e-02]],\n",
      "\n",
      "         [[-2.4311e-01,  1.6726e+00,  1.6682e-01,  ..., -1.0481e+00,\n",
      "           -2.7634e+00,  2.2741e-01],\n",
      "          [-1.4603e+00,  3.1239e-02,  3.8892e-01,  ...,  1.3443e-03,\n",
      "           -1.6754e+00,  3.1771e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ..., -7.8511e-01,\n",
      "           -3.2510e-01, -2.1300e-01],\n",
      "          [-3.9893e-01,  6.1469e-01, -3.9206e-01,  ...,  6.4928e-01,\n",
      "           -3.2944e-01, -2.4185e+00]],\n",
      "\n",
      "         [[ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.6488e+00,\n",
      "           -8.6854e-01, -8.0783e-01],\n",
      "          [-2.1516e+00, -2.4247e-01, -8.1713e-01,  ..., -1.8623e+00,\n",
      "           -1.1230e+00,  3.5013e-01]],\n",
      "\n",
      "         [[ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ..., -1.3121e+00,\n",
      "           -6.7044e-01, -1.1324e+00],\n",
      "          [ 4.3930e-01,  3.4082e-01, -1.2243e+00,  ...,  6.4975e-01,\n",
      "           -7.3862e-01, -2.1510e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  8.5980e-01,\n",
      "            3.2796e-01, -1.9442e+00],\n",
      "          [-8.9502e-01,  9.7357e-01,  8.5447e-01,  ...,  1.7637e+00,\n",
      "            9.1331e-01, -1.7033e+00]],\n",
      "\n",
      "         [[ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ..., -1.5965e+00,\n",
      "           -3.9380e-01, -4.3585e-01],\n",
      "          [-2.2103e+00,  4.4127e-01,  1.1554e+00,  ...,  9.8096e-01,\n",
      "            8.6736e-01, -2.3894e+00]],\n",
      "\n",
      "         [[ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ..., -1.1366e+00,\n",
      "           -2.8409e+00,  4.6711e-01],\n",
      "          [-1.9576e+00,  2.0176e-01, -4.1035e-02,  ...,  6.2708e-01,\n",
      "           -1.3601e+00, -3.9984e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          ...,\n",
      "          [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4397e-02, -6.9034e-02]],\n",
      "\n",
      "         [[-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3793e-03,\n",
      "           -5.2249e-01, -4.2095e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5678e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01],\n",
      "          ...,\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01],\n",
      "          [-1.0678e+00,  9.0885e-02, -4.5401e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6663e-03, -5.7117e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [ 4.5120e-01, -5.8035e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          ...,\n",
      "          [ 3.3361e-01,  1.5917e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01]],\n",
      "\n",
      "         [[-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00],\n",
      "          ...,\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1643e-01, -2.0784e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6103e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3793e-03,\n",
      "           -5.2249e-01, -4.2095e-01]],\n",
      "\n",
      "         [[ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00]],\n",
      "\n",
      "         [[ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5678e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01]],\n",
      "\n",
      "         [[ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01]],\n",
      "\n",
      "         [[ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4397e-02, -6.9034e-02],\n",
      "          [-1.0678e+00,  9.0885e-02, -4.5401e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6663e-03, -5.7117e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00]],\n",
      "\n",
      "         [[ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00]],\n",
      "\n",
      "         [[ 4.5120e-01, -5.8035e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3361e-01,  1.5917e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1643e-01, -2.0784e+00]],\n",
      "\n",
      "         [[ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01]],\n",
      "\n",
      "         [[ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6103e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[0.1385, 0.0325],\n",
      "        [0.1314, 0.0993]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from chop import MaseGraph\n",
    "import chop.passes as passes\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "model.config.problem_type = \"single_label_classification\"\n",
    "\n",
    "mg = MaseGraph(\n",
    "    model,\n",
    "    hf_input_names=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"labels\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "mg, _ = passes.init_metadata_analysis_pass(mg)\n",
    "mg, _ = passes.add_common_metadata_analysis_pass(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jw3621/adls/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model = torch.load(f)\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from chop import MaseGraph\n",
    "\n",
    "mg = MaseGraph.from_checkpoint(f\"{Path.home()}/tutorial_2_lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "/home/jw3621/adls/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.8136\n"
     ]
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset, get_trainer\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "trainer = get_trainer(\n",
    "    model=mg.model,\n",
    "    tokenized_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate_metric=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Evaluate accuracy\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chop.passes as passes\n",
    "import copy\n",
    "\n",
    "\n",
    "quant_config_search = []\n",
    "bit_widths = [4, 8, 16, 32]\n",
    "\n",
    "for width in bit_widths:\n",
    "    quantization_config = {\n",
    "        \"by\": \"type\",\n",
    "        \"default\": {\n",
    "            \"config\": {\n",
    "                \"name\": None,\n",
    "            }\n",
    "        },\n",
    "        \"linear\": {\n",
    "            \"config\": {\n",
    "                \"name\": \"integer\",\n",
    "                # data\n",
    "                \"data_in_width\": width,\n",
    "                \"data_in_frac_width\": width//2,\n",
    "                # weight\n",
    "                \"weight_width\": width,\n",
    "                \"weight_frac_width\": width//2,\n",
    "                # bias\n",
    "                \"bias_width\": width,\n",
    "                \"bias_frac_width\": width//2,\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    quant_config_search.append(copy.deepcopy(quantization_config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTQ & QAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jw3621/adls/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model = torch.load(f)\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "/home/jw3621/adls/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jw3621/adls/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model = torch.load(f)\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jw3621/adls/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.76104\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.449800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.438200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.440500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.405800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.408200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.402500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jw3621/adls/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model = torch.load(f)\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.83476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jw3621/adls/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.81388\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:42, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.439500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.428600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.395100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.398600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.395600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jw3621/adls/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model = torch.load(f)\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.83472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jw3621/adls/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.81356\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:42, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.438600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.428300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.394900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.399400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.394800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.83512\n"
     ]
    }
   ],
   "source": [
    "ptq_accuracies = []\n",
    "qat_accuracies = []\n",
    "\n",
    "\n",
    "for width, config in zip(bit_widths, quant_config_search):\n",
    "    mg = MaseGraph.from_checkpoint(f\"{Path.home()}/tutorial_2_lora\")\n",
    "    # Post-Training Quantization\n",
    "    mg, _ = passes.quantize_transform_pass(\n",
    "        mg,\n",
    "        pass_args=config,\n",
    "    )\n",
    "\n",
    "    trainer = get_trainer(\n",
    "        model=mg.model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "    )\n",
    "\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")\n",
    "    ptq_accuracies.append(eval_results[\"eval_accuracy\"])\n",
    "\n",
    "    # Quantization-Aware Training\n",
    "    # Evaluate accuracy\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")\n",
    "    qat_accuracies.append(eval_results[\"eval_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.76104, 0.81388, 0.81356]\n",
      "[0.5, 0.83476, 0.83472, 0.83512]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "baseline = 0.8136\n",
    "# ptq_accuracies = [0.5, 0.80272, 0.82164, 0.82084]\n",
    "# qat_accuracies = [0.5, 0.83148, 0.83392, 0.83428]\n",
    "print(ptq_accuracies)\n",
    "print(qat_accuracies)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(bit_widths, ptq_accuracies, marker='o', label='PTQ Accuracy')\n",
    "plt.plot(bit_widths, qat_accuracies, marker='o', label='QAT Accuracy')\n",
    "\n",
    "# Add baseline as a horizontal line\n",
    "plt.axhline(y=baseline, color='r', linestyle='--', label='Baseline')\n",
    "\n",
    "# Labeling and styling\n",
    "plt.title(\"IMDb Accuracy vs. Fixed-Point Width\")\n",
    "plt.xlabel(\"Fixed-Point Width (bits)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(bit_widths)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Pruning Exploration (Tutorial 4)**\n",
    "   - Take your best obtained model from Task 1 and rerun the pruning procedure, varying the sparsity from 0.1 to 0.9.  \n",
    "   - Plot a figure where:\n",
    "     - **x-axis:** Sparsity  \n",
    "     - **y-axis:** Highest achieved accuracy on the IMDb dataset  \n",
    "     - Follow the procedure in Tutorial 4.  \n",
    "   - Plot separate curves for **Random** and **L1-Norm** methods to evaluate the effect of different pruning strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import chop.passes as passes\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from chop import MaseGraph\n",
    "import chop.passes as passes\n",
    "from pathlib import Path\n",
    "from chop.tools import get_tokenized_dataset, get_trainer\n",
    "\n",
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\"\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jw3621/adls/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model = torch.load(f)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/home/jw3621/adls/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.8398\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9547' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9547/15625 03:14 < 02:04, 48.95 it/s, Epoch 3.05/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.389800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.385300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.394900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.385200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.392400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.397800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.367300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.360400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.371800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.366100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.355700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.370800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.359400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.360100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.373900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.357100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.361800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pruned_acc_random = []\n",
    "finetuned_acc_random = []\n",
    "\n",
    "pruned_acc_l1 = []\n",
    "finetuned_acc_l1 = []\n",
    "\n",
    "possible_sparsity = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "for strategy in ['l1-norm', 'random']:\n",
    "    for sparsity in possible_sparsity:\n",
    "        # load model\n",
    "        mg = MaseGraph.from_checkpoint(f\"{Path.home()}/tutorial_3_qat_32\")\n",
    "\n",
    "        pruning_config = {\n",
    "            \"weight\": {\n",
    "                \"sparsity\": sparsity,\n",
    "                \"method\": strategy,\n",
    "                \"scope\": \"local\",\n",
    "            },\n",
    "            \"activation\": {\n",
    "                \"sparsity\": sparsity,\n",
    "                \"method\": strategy,\n",
    "                \"scope\": \"local\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "        mg, _ = passes.prune_transform_pass(mg, pass_args=pruning_config)\n",
    "\n",
    "        trainer = get_trainer(\n",
    "            model=mg.model,\n",
    "            tokenized_dataset=dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            evaluate_metric=\"accuracy\",\n",
    "            num_train_epochs=5,\n",
    "        )\n",
    "\n",
    "        # Evaluate accuracy\n",
    "        eval_results = trainer.evaluate()\n",
    "        print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")\n",
    "        if strategy == 'random':\n",
    "            pruned_acc_random.append(eval_results['eval_accuracy'])\n",
    "        if strategy == 'l1-norm':\n",
    "            pruned_acc_l1.append(eval_results['eval_accuracy'])\n",
    "\n",
    "\n",
    "        # further fine-tunning\n",
    "        trainer.train()\n",
    "        eval_results = trainer.evaluate()\n",
    "        print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")\n",
    "        if strategy == 'random':\n",
    "            finetuned_acc_random.append(eval_results['eval_accuracy'])\n",
    "        if strategy == 'l1-norm':\n",
    "            finetuned_acc_l1.append(eval_results['eval_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "print(pruned_acc_random)\n",
    "print(finetuned_acc_random)\n",
    "print(pruned_acc_l1)\n",
    "print(finetuned_acc_l1)\n",
    "# pruned_acc_random, finetuned_acc_random, pruned_acc_l1, finetuned_acc_l1\n",
    "\n",
    "# 1. Compute the best (maximum) accuracy at each sparsity for both strategies.\n",
    "best_acc_random = [\n",
    "    max(p, f) for p, f in zip(pruned_acc_random, finetuned_acc_random)\n",
    "]\n",
    "best_acc_l1 = [\n",
    "    max(p, f) for p, f in zip(pruned_acc_l1, finetuned_acc_l1)\n",
    "]\n",
    "\n",
    "# 2. Create the plot.\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(possible_sparsity, best_acc_random, marker='o', label='Random')\n",
    "plt.plot(possible_sparsity, best_acc_l1, marker='s', label='L1-Norm')\n",
    "\n",
    "plt.xlabel('Sparsity')\n",
    "plt.ylabel('Highest Achieved Accuracy')\n",
    "plt.title('Comparison of Random vs. L1-Norm Pruning Strategies')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(f\"{Path.home()}/prune_plot\", dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jw3621/prune_plot\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "print(f\"{Path.home()}/prune_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase-adls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
